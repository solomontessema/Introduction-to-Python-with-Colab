{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solomontessema/Introduction-to-Python-with-Colab/blob/master/notebooks/Day_12_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeDwzwQ0n3fH"
      },
      "source": [
        "<table>\n",
        "  <tr>\n",
        "    <td><img src=\"https://ionnova.com/img/ionnova_logo_name_2.png\" width=\"120px\"></td>\n",
        "    <td><h1>Day 12: RAG (Retrieval-Augmented Generation)</h1></td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2gpufwQLJ5oc"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "API_KEY = os.getenv(\"GPT_API_KEY\")\n",
        "client = OpenAI(api_key=API_KEY)\n",
        "\n",
        "# Load knowledge base (simple text chunks for demo)\n",
        "def load_knowledge_base():\n",
        "    with open(\"knowledge_base.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        chunks = f.read().split(\"\\n\\n\")  # Assume chunks are separated by double newlines\n",
        "        #print(chunks)\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def chat_with_rag():\n",
        "    print(\"Welcome to IonnovaBot! Type 'exit' to quit.\\n\")\n",
        "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant that uses external knowledge to answer questions.\"}]\n",
        "    kb_chunks = load_knowledge_base()\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"IonnovaBot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Retrieve context\n",
        "\n",
        "        context = \"\\n---\\n\".join(kb_chunks)\n",
        "\n",
        "        # Inject context into prompt\n",
        "        messages.append({\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {user_input}\"})\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=messages,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        reply = response.choices[0].message.content\n",
        "        print(f\"IonnovaBot: {reply}\")\n",
        "        messages.append({\"role\": \"assistant\", \"content\": reply})\n",
        "\n",
        "chat_with_rag()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}