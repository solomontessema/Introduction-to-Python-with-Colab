{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solomontessema/Introduction-to-Python-with-Colab/blob/master/notebooks/Day_11_API_Call_to_GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "  <tr>\n",
        "    <td><img src=\"https://ionnova.com/img/ionnova_logo_name_2.png\" width=\"120px\"></td>\n",
        "    <td><h1>Day 11: API Call to GPT</h1></td>\n",
        "  </tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "AeDwzwQ0n3fH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Comparison of Leading AI Models</h2>\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "      <th>Model</th>\n",
        "      <th>Free Tier</th>\n",
        "      <th>Context Window</th>\n",
        "      <th>Prompt Limits</th>\n",
        "      <th>Multimodal Output</th>\n",
        "      <th>Cost (Paid Tier)</th>\n",
        "      <th>Agentic Suitability</th>\n",
        "      <th>Model Owner</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>GPT-4o / GPT-5</td>\n",
        "      <td>❌ No</td>\n",
        "      <td>128k–200k</td>\n",
        "      <td>Unlimited</td>\n",
        "      <td>Text only</td>\n",
        "      <td>$2.50–$10 per 1M tokens</td>\n",
        "      <td>✅ Excellent (tool use, planning, reasoning)</td>\n",
        "      <td>OpenAI</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Gemini 2.5 Pro</td>\n",
        "      <td>❌ No</td>\n",
        "      <td>Up to 1M</td>\n",
        "      <td>5/day (free), 100/day (paid)</td>\n",
        "      <td>Text, image, audio, video</td>\n",
        "      <td>$19.99/month (Advanced)</td>\n",
        "      <td>✅ Excellent (multimodal, long context)</td>\n",
        "      <td>Google DeepMind</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Gemini 2.5 Flash</td>\n",
        "      <td>✅ Yes</td>\n",
        "      <td>Up to 1M</td>\n",
        "      <td>~5–10/day (free), scalable</td>\n",
        "      <td>Text, image, audio, video</td>\n",
        "      <td>Scales with Vertex AI usage</td>\n",
        "      <td>✅ Great (fast, multimodal, lightweight agents)</td>\n",
        "      <td>Google DeepMind</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Claude 3.5 Sonnet</td>\n",
        "      <td>❌ No</td>\n",
        "      <td>200k</td>\n",
        "      <td>Generous (web only)</td>\n",
        "      <td>Text + image input</td>\n",
        "      <td>$20/month (Pro)</td>\n",
        "      <td>✅ Excellent (ethical reasoning, long docs)</td>\n",
        "      <td>Anthropic</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>LLaMA 3 (Meta)</td>\n",
        "      <td>✅ Yes (self-hosted)</td>\n",
        "      <td>Varies by size</td>\n",
        "      <td>Unlimited</td>\n",
        "      <td>Text only</td>\n",
        "      <td>Free (self-hosted)</td>\n",
        "      <td>✅ Great (custom agents, open-source control)</td>\n",
        "      <td>Meta</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Mistral / Mixtral</td>\n",
        "      <td>✅ Yes (via hosts)</td>\n",
        "      <td>~32k</td>\n",
        "      <td>Unlimited</td>\n",
        "      <td>Text only</td>\n",
        "      <td>Low-cost via Replicate/Together</td>\n",
        "      <td>✅ Fast, efficient agents</td>\n",
        "      <td>Mistral AI</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Command R+ (Cohere)</td>\n",
        "      <td>✅ Yes (paid)</td>\n",
        "      <td>~100k</td>\n",
        "      <td>Unlimited</td>\n",
        "      <td>Text only</td>\n",
        "      <td>Competitive pricing</td>\n",
        "      <td>✅ Strong for RAG and enterprise agents</td>\n",
        "      <td>Cohere</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n"
      ],
      "metadata": {
        "id": "ZupzEQ_8IWrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "API_KEY = \"Your API KEY\"\n",
        "\n",
        "client = genai.Client(api_key=\"Your_API_Key\")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=\"Explain how AI works in a few words. Answer that in 200 words\",\n",
        ")\n",
        "\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "id": "oPCVxOkMrJZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2gpufwQLJ5oc"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"Your_API_Key\")\n",
        "\n",
        "def chat_with_gpt():\n",
        "    print(\"Welcome to IonnovaBot! Type 'exit' to quit.\\n\")\n",
        "    messages = [{\"role\": \"system\", \"content\": \"You are a friendly assistant.\"}]\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"IonnovaBot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=messages,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        reply = response.choices[0].message.content\n",
        "\n",
        "\n",
        "        print(f\"IonnovaBot: {reply}\")\n",
        "\n",
        "        messages.append({\"role\": \"assistant\", \"content\": reply})\n",
        "\n",
        "chat_with_gpt()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}